{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surprising-horizon",
   "metadata": {},
   "source": [
    "Entre algunos análisis que miro frecuentemente están los análisis de mercado, específicamente quantitive analysis(QA), es una rama muy amigable del análisis de mercado que creo que todos deberían conocer,  aporta un plus a la gestión tanto en el mercado financiero como en la vida diaria , por tal razón he decido realizar una series de guías de cómo utilizar e interpretar estás las herramientas estadísticas que tenemos a disposición para medir, modelar y comprender el comportamiento del mercado. \n",
    "Por ahora me planteo tres guías de iniciación, serán muy sencillas, son los primeros pasos que se realizan para los estudios de mercado.\n",
    "\n",
    "\n",
    "- Obteniendo Data desde yahoo Finance \n",
    "- Herramientas básicas estadísticas (Desviación, Normalidad, skewness, Kurtosis y más)\n",
    "- Introducción a la Optimización de Portafolio\n",
    "\n",
    "Estás son las primeras guías que tengo en mente, algo que espero que tomen en cuenta es que utilizaré conceptos en inglés, por ejemplo no suelo decir \"acciones\", sino shares o equities, igual intentare traducir lo más que pueda, pero el material con el estudio es en inglés y no conozco todas las traducciones, igual en su defecto estaré explicando cada concepto.\n",
    "\n",
    "Espero las guías sean de mucha utilidad, estaré avisando por mis redes cuando haga publicaciones, así que los invito a seguirme, esto lo hago porque me gusta sin embargo hay un botón de PayPal para quien quiera invitarme un café ya que es la forma de yo saber que hay gente muy interesada en lo que escribo.\n",
    "\n",
    "Por último y más importante, cualquier comentario o opinión emitida aquí no es una recomendación ni sugerencia en cuanto a administrar su portafolio de inversión, cada quien es responsable de las desición que tome,sin más dilación comencemos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-nursing",
   "metadata": {},
   "source": [
    "En esta oportunidad tomare información de acciones del mercado venezolano para explicar como normalizo los precios al precio $ dado la inestabilidad que hay con el VEF, de esta forma se facilitan muchos cálculos, sin embargo, lo que quiero decir es que esto funciona para cualquier mercado que se encuentre en yahoo finance.\n",
    "\n",
    "Para obtener información de las principales acciones ofertas en el mercado venezolano, se hara uso de la API de yahoo finance donde se encuentran registro de los precios historicos y actuales de cada de una de las acciones con las que se quiera comerciar,por otro lado, a la fecha de hoy venezuela sufre un periodo de crisis economica que mantiene una inestabilidad en la moneda nacional,lo cual no solo dificulta los calculos a nivel historico, es decir, hacer un analisis con data del 2018 hasta hoy en día puede sercasi imposible por la diferencia en el valor de la moneda.\n",
    "Para el problema anterior estarizaremos y facilitar los calculos, estandarizamos los precios de los activos a precio de $, para conseguir historico cambiario del par USD/VEF, descargar el csv desde el 2018 [USD/VEF](https://www.investing.com/currencies/usd-vef-historical-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-shark",
   "metadata": {},
   "source": [
    "recuerda instalar las siguientes librerias\n",
    "\n",
    "- !pip install pandas #libreria que ofrece un framework amigable para el manejo de tablas\n",
    "- !pip numpy  #libreria para el manejo de operaciones matematicas\n",
    "- !pip matplotlib  #libreria para graficar \n",
    "- !pip yfinance #API de yahoo finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "convinced-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance  as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-poster",
   "metadata": {},
   "source": [
    "El primero paso que daremos consistira en hacer lectura de la archivo descargado desde investing,\n",
    "la estructura de este archivo es basicamente un fecha, el precio promedio, el precio con que abre el mercado,\n",
    "su valor más alto, su valor más bajo <<estos tres son iguales por alguna extraña razon>> y el porcentaje de cambio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stuck-adult",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'assets/USD_VES.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8d851101c49e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'assets/USD_VES.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hramo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hramo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hramo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hramo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hramo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hramo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hramo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'assets/USD_VES.csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv('assets/USD_VES.csv', header=0, index_col=0, parse_dates=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-pencil",
   "metadata": {},
   "source": [
    "\n",
    "Una configuración amigable para la lectura es, tomar la primera fila como los header que son los nombres de la columna, \n",
    "colocar la fecha como indice y indicarle que el indice es una fecha, ademas de eso indicaremos que solo necesitamos \n",
    "la columna de precio, ordenamos y renombramos la columna con un nombre más claro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "usdVEF = pd.read_csv('assets/USD_VES.csv', header=0, index_col=0, parse_dates=True )['Price']\n",
    "usdVEF = pd.DataFrame(usdVEF.sort_index()) #ordenamos de manera ascendente\n",
    "usdVEF.columns = ['Bs/USD$']  #renombramos la columna\n",
    "usdVEF.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-coast",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "committed-marriage",
   "metadata": {},
   "source": [
    "Ahora comencemos con lo bueno, haremos lectura de unas pocas acciones para entender el funcionamiento.\n",
    "- 'BNC.CR' \n",
    "- 'MVZ-B.CR'\n",
    "- 'CIE.CR' \n",
    "- 'FNC.CR'\n",
    "\n",
    "primero creemos un DataFrame vacio, basicamente lo que haremos se empaquetar todos los datos allí, solo ten presente eso.\n",
    "Haremos lectura con de nuestras shares con la funcion Ticker, esta se encuentra dentro de la liberia de yahoo finance, esta funcion prepara los datos para ser leidos es como \"oye prepara la shares de BNC que va ser leida\", \n",
    "una vez preparada hacemos lectura deacuerdo al periodo que queremos, por lo general mientras más datos tengas mejor, pero por ahora igual que con el par VEF/USD, aqui necesitamo solo el precio, y tomaremos solo 3 años de datos.\n",
    "\n",
    "Esto funciona para un shares, pero ahora queremos varios por lo requeriremos hacer el recorrido varias veces,\n",
    "además de eso queremos meter todo junto en una misma tabla, o concatenar todos los datos.\n",
    "\n",
    "Meteré toda esta información en una función, una función nos facilitará mucho la vida, solo tendremos\n",
    "que cambiar la lista de shares de la que queremos hacer lectura y función hará el mismo trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "powerful-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "equities = ['PTN.CR', 'MVZ-B.CR', 'FNC.CR']\n",
    "def data(shares):\n",
    "    df = pd.DataFrame()\n",
    "    for i in shares:\n",
    "        read = yf.Ticker(i)\n",
    "        hist = read.history(period=\"3y\")['Close']\n",
    "        data = pd.DataFrame(hist)\n",
    "        data['Close'].columns = [i]\n",
    "        data = data.loc[~data.index.duplicated(keep='first')]\n",
    "        df = pd.concat([df, data], axis=1)\n",
    "        \n",
    "    df.columns = shares\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "verified-france",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTN.CR</th>\n",
       "      <th>MVZ-B.CR</th>\n",
       "      <th>FNC.CR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-16</th>\n",
       "      <td>0.139857</td>\n",
       "      <td>24.606991</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-17</th>\n",
       "      <td>0.139857</td>\n",
       "      <td>24.606991</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18</th>\n",
       "      <td>0.134862</td>\n",
       "      <td>29.528389</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-19</th>\n",
       "      <td>0.134862</td>\n",
       "      <td>29.528389</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20</th>\n",
       "      <td>0.139857</td>\n",
       "      <td>29.528389</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PTN.CR   MVZ-B.CR  FNC.CR\n",
       "Date                                   \n",
       "2018-04-16  0.139857  24.606991   0.286\n",
       "2018-04-17  0.139857  24.606991   0.340\n",
       "2018-04-18  0.134862  29.528389   0.400\n",
       "2018-04-19  0.134862  29.528389   0.400\n",
       "2018-04-20  0.139857  29.528389   0.400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data(equities)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-disposition",
   "metadata": {},
   "source": [
    "Ahora que tenemos los datos del precio del dolar y el precio de nuestras shares, uniremos todo para estandarizar los precios de las shares, esto simplemente es una idea de facilitar los calculos debido a la hiperinflación en la que se encuentra la economia en Venezuela lo que ocasiona una desvalorización de la moneda Bs y complica los calculos debido a la diferencia de precios.\n",
    "\n",
    "Luego de unir los datos, limpearemos un poco nuestro jardin, el formato de bs/USD$ son interpreados como string, asi que modificaremos eso para poder trabajar con el valor, luego estandarizamos, divimos el precio de nuestra accion al precio del dolar del mismo día.\n",
    "Por último, tenemos una diferencia en las fechas entre los dataframe, la fecha de VEF/USD esta desde el enero 2018, mientra que alguna de nuestras shares solo tenemos data a partir de abril, esas diferencia entre fechas es rellenada con valores NaN, estos valores indican la ausencia de datos, removeremos todas esas filas ya que no presetan información de los precios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rising-marking",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'usdVEF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-deb50d2d7409>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfUSD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musdVEF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdfUSD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Bs/USD$'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfUSD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Bs/USD$'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdfUSD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfUSD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfUSD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Bs/USD$'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'usdVEF' is not defined"
     ]
    }
   ],
   "source": [
    "dfUSD = usdVEF.join(df)\n",
    "dfUSD['Bs/USD$'] = dfUSD['Bs/USD$'].str.replace(',','').astype(np.float64)\n",
    "dfUSD = dfUSD.iloc[:,1:].div(dfUSD['Bs/USD$'],axis=0).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUSD.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-mother",
   "metadata": {},
   "source": [
    "El primer concepto que revisaremos será el performance de la shares, en español se refiere al rendimiento o retorno.\n",
    "Recordemos que el retorno para un tiempo $t$ a un tiempo ${t-1}$ esta dato por :\n",
    "\n",
    "$$ R_{t,t+1} = \\frac{P_{t+1}-P_{t}}{P_{t}}$$\n",
    "\n",
    "una alternativa muy común que veo en excel es usar esta.\n",
    "\n",
    "$$ R_{t,t+1} = \\frac{P_{t+1}}{P_{t}} - 1$$\n",
    "\n",
    "Secillamente le estamos pidiendo que compare el precio con un precio anterior y nos muestre el resultado en terminos de porcentaje.\n",
    "\n",
    "Es una función sencilla pero antes de que intentes algo como este código,\n",
    "\n",
    "```python\n",
    "\n",
    "dfUSD.iloc[1:]/dfUSD.iloc[:-1].values - 1\n",
    "\n",
    "```\n",
    "\n",
    "recuerda necesitas forzar un lag en la serie de tiempo porque trabaja con un tiempo adelante, y de esa forma aunque el calculo esta bien planteado acorde al punto de referencia(tiempo) no estara bien ordenado, te invito a probar como ejercicio.\n",
    "\n",
    "Para resolver este problema de periodos python tiene la función [shift()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html), esta función permite mover un paso adelante los registros, intetemos!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exceptional-anthropology",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfUSD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-358cae0fb681>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmvzbR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfUSD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FNC.CR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdfUSD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FNC.CR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmvzbR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfUSD' is not defined"
     ]
    }
   ],
   "source": [
    "mvzbR = dfUSD['FNC.CR']/dfUSD['FNC.CR'].shift(1) -1\n",
    "mvzbR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-element",
   "metadata": {},
   "source": [
    "Entendiendo como funciona el calculo, y como puedes hacerlo por ti mismo, ahora te dare el camino fácil, es la función de python [ptc_change()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pct_change.html)\n",
    "\n",
    "<cite>\"Percentage change between the current and a prior element\".</cite> esta es la definición que ofrece la documentación, justo lo que queremos, veamos si funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvzbR = dfUSD['FNC.CR'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvzbR.plot(figsize=(12,7))\n",
    "plt.grid(alpha=0.5)\n",
    "plt.title('Performance FNC 2018-2021')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvzbR['2021':'2021'].hist(bins=30, figsize=(7,5))\n",
    "plt.title('performance distribution FNC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-heating",
   "metadata": {},
   "source": [
    "Por último quiero que miremos algo muy interesante, y es el indexado que seleccionamos al comienzo, esto también será mucha más utilidad más adelante cuando necesitemos comparar $t$ con ${t-n}$, no profundizare en eso ahora, simplemente quiero mostrar cómo con el índice podemos elegir los periodos de estudio, es algo muy sencillo,tenemos que seleccionar el periodo que queremos evaluar como se muestra en el  siguiente código.\n",
    "\n",
    "\n",
    "```python\n",
    "data['fecha inicio':'fecha final']....\n",
    "```\n",
    "\n",
    "Veamos si funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvzbR['2021':'2021'].plot(figsize=(12,7))\n",
    "plt.grid(alpha=0.5)\n",
    "plt.title('Performance FNC año 2021')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-organizer",
   "metadata": {},
   "source": [
    "Esto puedes usarlo para graficar, en tablas y cálculos, una genialidad.\n",
    "\n",
    "Bueno esto es todo por ahora, espero que haya sido muy ilustrativo y que hayas aprendido bastante, sin más que decirte espero verte en la segunda parte de este mini-turorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-singer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-quest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-straight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
